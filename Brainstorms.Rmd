---
title: "Brainstorms for leanr lessons"
author: "by P. Lombardo"
output:
  html_document: default
---
```{r}
library(tidyverse)
library(lubridate)
```


## logical-vectors lesson
`%in%` and `grepl()` stuff
```{r}
small_iris<-iris %>% slice(c(1:2, 51, 52, 101:102)) %>%
    select(Species, Petal.Width)

small_iris$Species =="setosa"

small_iris$Species %in% c("versicolor","virginica")

grepl("v",small_iris$Species)
grepl("s",small_iris$Species)
grepl("i",small_iris$Species)
```

Tweet source:

[https://github.com/madhuchaliyan/nlp](https://github.com/madhuchaliyan/nlp)
redirected back to kaggle.

in cli, used 
```
head -1000 twcs.csv >> new.csv
```

```{r}
tweet_df<-read.csv('logical-vectors/data/twcs_small.csv',header=T)
tweet_df2<-tweet_df %>%
    mutate(text = gsub("(shit|damn|fuck|cock|pussy)","*swear*",text))
write.csv(tweet_df2,'twcs_small_clean.csv',row.names = F)
```

```{r}
tweet_df %>% names()
dim(tweet_df)
grepl("friend",tweet_df$text) %>% sum()
grepl("@",tweet_df$text) %>% sum()
grepl("#",tweet_df$text) %>% sum()
grepl("good",tweet_df$text) %>% sum()
grepl("(McDonald's|Chipotle)",tweet_df$text) %>% sum()

```




## Filtering lesson

### Cleaning data set 
[Top 200 movies of 2023](https://www.kaggle.com/datasets/mohammadrizwansajjad/top-200-movies-of-2023) 

```{r}
movies<-read.csv('data/Movies_Top_200.csv',header =T,
                 na.strings = "'-")
```

```{r}
movies %>%
    mutate(
        Release.month = month(as_date(Release.Date), label = T),
        Release.weekday = wday(as_date(Release.Date), labe = T),
        Release.day = day(as_date(Release.Date)),
        Total.Gross.Million = round(as.numeric(gsub("\\$","",gsub(",","",Total.Gross)))/1000000,2),
        Theaters.Count = as.numeric(gsub(",","",Theaters))
    ) %>% select(
        Rank, Title, Total.Gross.Million, Release.month, Release.weekday, Release.day, Theaters.Count, Distributor
    ) -> movies2
```

```{r}
write.csv(movies2, 'Top_200_movies_cleaned.csv',row.names = F)
```

### brainstorm
```{r}
movies<-movies2
sum(movies2$Release.weekday %in% c("Fri","Sat"))/nrow(movies2)

movies2 %>%
    filter(grepl("\\s[Dd]ead\\s",Title)) %>%
    select(Title)

movies2 %>%
    filter(grepl("Dead",Title)) %>%
    select(Title)

movies2 %>%
    filter(grepl("Man",Title),
           Total.Gross.Million <500,
           Total.Gross.Million >200) %>%
    select(Title)

movies2 %>%
    filter(grepl("me",Title),
           Rank <= 100,
           Total.Gross.Million>100,
           Total.Gross.Million<300) %>%
    select(Title)
movies %>% select(Title)

```

```{r}
grepl("@sprintcare",tweets$text) %>% sum()
grepl("@[Vv]erizon",tweets$text) %>% sum()
```


```{r}
tweets %>%
    filter(author_id=="sprintcare") %>%
    select(text)

tweets %>%
    filter(grepl("@sprintcare",text)) %>%
    select(text)

tweets %>%
    filter(author_id=="SpotifyCares") %>%
    select(text)

(tweets$author_id %>% unique())[tweets$author_id %>% unique() %>% grepl("care",.)]

(tweets$author_id %>% unique())[tweets$author_id %>% unique() %>% grep("^[A-Za-z]",.)]

tweets %>%
    filter(grepl("concern",text)) %>%
    select(author_id,text)
```
```{r}
tweets %>%
    filter(grepl("Help",author_id))
```






